---
title: "Jason's Notes"
permalink: /notes/
author_profile: true
---

Deep Learning
1. [Logistic regression](/files/lr.pdf)
2. [Backprop for logistic regression](/files/IMG_3902.JPG)
3. [Backprop for a two-layer neural net](/files/IMG_3903.JPG)
4. [Deriving backprop](/files/deriving_backprop.pdf)
5. [A pure numpy neural net in less than 200 lines (code)](https://github.com/jasonwei20/jasonwei20.github.io/blob/master/code/numpy_neural_net.py)
5. [Regularization, activation functions, initialization, optimization, batch norm](/files/improving_dnns.pdf)
6. [Convolutional neural nets](/files/cnns.pdf)
7. [Recurrent neural nets](/files/rnns.pdf)

NLP
1. [Word embeddings](/files/word_embeddings.pdf)
2. [Attention](/files/attention.pdf)
3. [Transformers](/files/transformers.pdf)
4. [BERT](/files/bert.pdf)

Machine Learning
1. [Decision trees and random forests](/files/IMG_3905.JPG)
2. [Support vector machines and kernels](/files/IMG_3904.JPG)
3. [*k*-means](/files/k-means.pdf)

Computer Science
* [Algorithms](/files/algo_notes.pdf)

To do
1. XLNet
2. BART
3. SimCLR

Most of my ML/DL notes are from Andrew Ng's *Deep Learning* and *Machine Learning* Coursera courses. I also really liked *Hands-On Machine Learning with Scikit-Learn and Tensorflow* by Aurélien Géron.

My NLP notes are based on content from Andrew Ng, Graham Neubig, papers, and YouTube explanations.

People to follow
1. Anything written by Sam Greydanus
1. Nanyun Peng's work on creative language generation
1. Work from Ryan Cotterell's lab
1. Tim Althoff's work on mental health
1. Jacob Andreas
1. Robin Jia